import json
import os
import requests
from typing import List, Dict, Any, Tuple
import logging

HISTORY_FILE = "tmp/messages.json"
LM_STUDIO_API_URL = "http://localhost:1234/v1"


def make_log_path(log_dir, scenario_filename, character_filename):
    if not scenario_filename or not character_filename:
        raise ValueError("scenario_filenameã¨character_filenameã¯å¿…é ˆã§ã™")
    base = f"{os.path.splitext(scenario_filename)[0]}__{os.path.splitext(character_filename)[0]}.json"
    return os.path.join(log_dir, base)


def load_history(
    system_message: str, scenario_filename: str = None, character_filename: str = None
) -> List[Dict[str, Any]]:
    """å±¥æ­´ãƒ•ã‚¡ã‚¤ãƒ«ãŒã‚ã‚Œã°èª­ã¿è¾¼ã¿ã€ãªã‘ã‚Œã°systemãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã§åˆæœŸåŒ–ã—ãŸãƒªã‚¹ãƒˆã‚’è¿”ã™"""
    log_dir = os.environ.get("TMP_DIR") or os.path.join(
        os.path.dirname(__file__), "../tmp"
    )
    log_path = make_log_path(log_dir, scenario_filename, character_filename)
    if os.path.exists(log_path):
        with open(log_path, encoding="utf-8") as f:
            messages = json.load(f)
            print("ğŸ“¦ å±¥æ­´èª­ã¿è¾¼ã¿å®Œäº†")
            return messages
    else:
        print("ğŸ†• æ–°è¦ã‚»ãƒƒã‚·ãƒ§ãƒ³")
        return [{"role": "system", "content": system_message}]


def save_history(
    messages: List[Dict[str, Any]],
    scenario_filename: str = None,
    character_filename: str = None,
) -> None:
    """å±¥æ­´ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜ã™ã‚‹"""
    log_dir = os.environ.get("TMP_DIR") or os.path.join(
        os.path.dirname(__file__), "../tmp"
    )
    log_path = make_log_path(log_dir, scenario_filename, character_filename)
    os.makedirs(os.path.dirname(log_path), exist_ok=True)
    with open(log_path, "w", encoding="utf-8") as f:
        json.dump(messages, f, ensure_ascii=False, indent=2)


def query_lmstudio(
    text: str, messages: List[Dict[str, Any]], model_id: str
) -> Tuple[str, List[Dict[str, Any]]]:
    """LM Studio APIã«ä¼šè©±ã‚’æŠ•ã’ã¦å¿œç­”ã‚’å–å¾—ã™ã‚‹"""
    print(f"ğŸ’¬ LM Studioé€ä¿¡é–‹å§‹")
    headers = {"Content-Type": "application/json"}
    payload = {
        "model": model_id,
        "messages": messages,
    }
    try:
        response = requests.post(
            f"{LM_STUDIO_API_URL}/chat/completions",
            headers=headers,
            json=payload,
            timeout=60,
        )
        response.raise_for_status()
        data = response.json()
        content = data["choices"][0]["message"]["content"].strip()
        print(f"ğŸ’¬ AIå¿œç­”: {content}")
        return content, messages
    except Exception as e:
        logging.warning(f"âš ï¸ LM Studio ã‚¨ãƒ©ãƒ¼: {e}")
        return "", messages


def get_model_list() -> List[str]:
    """åˆ©ç”¨å¯èƒ½ãªãƒ¢ãƒ‡ãƒ«ä¸€è¦§ã‚’å–å¾—ã™ã‚‹"""
    try:
        response = requests.get(f"{LM_STUDIO_API_URL}/models", timeout=10)
        response.raise_for_status()
        data = response.json()
        model_ids = [model["id"] for model in data.get("data", [])]
        return model_ids
    except Exception as e:
        logging.warning(f"âš ï¸ ãƒ¢ãƒ‡ãƒ«ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return []


def chat_with_lmstudio(
    text: str, messages: List[Dict[str, Any]], model_id: str
) -> Tuple[str, List[Dict[str, Any]]]:
    """
    ãƒ¦ãƒ¼ã‚¶ãƒ¼ç™ºè¨€ã‚’å±¥æ­´ã«è¿½åŠ ã—ã€AIå¿œç­”ã‚‚å±¥æ­´ã«è¿½åŠ ã—ã¦è¿”ã™
    """
    messages.append({"role": "user", "content": text})
    reply, _ = query_lmstudio(text, messages, model_id)
    messages.append({"role": "assistant", "content": reply})
    return reply, messages
